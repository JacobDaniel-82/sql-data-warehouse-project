# ğŸ¢ Data Warehouse Medallion Architecture: End-to-End SQL Pipeline

## ğŸŒŸ Project Overview
This project demonstrates the design and implementation of a modern **Data Warehouse** using the **Medallion Architecture** (Bronze, Silver, Gold). The goal was to build a robust ETL (Extract, Transform, Load) pipeline that integrates disparate data from **CRM** and **ERP** systems into a centralized, reporting-ready Star Schema.

By moving data through three distinct layers, the architecture ensures data lineage, high quality, and a "Single Version of Truth" for business stakeholders.

---

## ğŸ—ï¸ Architecture Design
The warehouse is built on the **Medallion Architecture** principle:

* **Bronze Layer (Raw):** Landing zone for raw data as-is from source systems.
* **Silver Layer (Cleansed):** Data is standardized, deduplicated, and cleansed of "dirty" values.
* **Gold Layer (Curated):** Business-level views organized in a Star Schema (Dimensions & Facts) optimized for analytics.

![Architecture Diagram](docs/architecture.png)

---

## ğŸ› ï¸ Technology Stack
* **Database:** SQL Server (T-SQL)
* **Modeling:** Star Schema (Dimensional Modeling)
* **Tools:** Git, Draw.io (Documentation), Notion (Project Planning), Google Gemini (Documentation)
* **Environment:** Medallion Architecture (Bronze, Silver, Gold)

## ğŸ“ Repository Structure
```text
â”œâ”€â”€ datasets/             # Raw CSV data (CRM & ERP)
â”œâ”€â”€ docs/                 # Architecture, Data Model, & Diagrams (PNG/Draw.io)
â”‚   â”œâ”€â”€ data_catalog.md   # Data dictionary & column descriptions
â”‚   â””â”€â”€ naming_conventions.md # Project governance & naming rules
â”œâ”€â”€ scripts/              # SQL scripts for DDL and Stored Procedures
â”‚   â”œâ”€â”€ bronze/           # Extraction logic
â”‚   â”œâ”€â”€ silver/           # Transformation & Cleaning logic
â”‚   â”œâ”€â”€ gold/             # Reporting Views (Star Schema)
â”‚   â””â”€â”€ init_database.sql # Database initialization
â”œâ”€â”€ tests/                # Data Quality & Validation scripts
â””â”€â”€ README.md             # Project documentation
```
---

## ğŸš€ The ETL Process

### 1. Bronze: Extraction (The "E" in ETL)
Data is ingested from external CSV files using high-performance `BULK INSERT` commands. No transformations are performed here to maintain an audit trail of the original raw data.
* **Script:** `scripts/bronze/proc_load_bronze.sql` - [click here](scripts/bronze)

### 2. Silver: Transformation (The "T" in ETL)
This layer performs heavy lifting, including:
* **Deduplication:** Using `ROW_NUMBER()` to ensure unique customer records.
* **Data Standardization:** Mapping inconsistent values (e.g., 'M' -> 'Male', 'DE' -> 'Germany').
* **Data Type Conversion:** Converting `INT` date formats to `DATE` objects.
* **Audit Columns:** Adding `dwh_create_date` for traceability.
* **Script:** `scripts/silver/proc_load_silver.sql` - [click here](scripts/silver)

### 3. Gold: Loading (The "L" in ETL)
Final reporting views are created using a **Dimensional Model**. This layer links CRM and ERP data into a seamless experience for BI tools.
* **Dim_Customers:** Merged view of CRM & ERP customer data.
* **Dim_Products:** Filtered to show only current, non-historical products.
* **Fact_Sales:** Central transaction table linking to dimensions via surrogate keys.
* **Script:** `scripts/gold/ddl_gold.sql` - [click here](scripts/gold)

**Data Model**
![Data Model](docs/data_model.png)

**Data Flow**
![Data Flow](docs/data_flow.png)

---

## âœ… Data Quality & Governance
A critical component of this project is the **Data Quality Framework** found in the `/tests` folder.

* **Discovery Checks:** Identifying nulls, duplicates, and malformed data in the Bronze layer.
* **Verification Checks:** Confirming that all cleaning logic was successfully applied in the Silver layer.
* **Referential Integrity:** Ensuring every sale in the Fact table has a valid corresponding Customer and Product key (No "orphan" records).

**Project Standards:**
* Strict adherence to `snake_case` naming conventions.
* Use of **Stored Procedures** for modular and reusable ETL code.
* Full **Data Catalog** documentation for business users.

---

## ğŸ’¡ Why This Project Matters
In many organizations, data is trapped in "Silos" (CRM and ERP systems don't talk to each other). This project bridges that gap.

**The Challenge:**
* **Dirty Data:** Inconsistent gender codes (M, F, Male, Female).
* **Mismatched Keys:** ERP and CRM systems using different IDs for the same customer.
* **Data Integrity:** Orders with prices that don't match the quantity.

**The Solution:**
* **Silver Layer Standardization:** Centralized all logic to fix "dirty" data once, so analysts don't have to.
* **Master Data Integration:** Created a mapping logic to link CRM and ERP records into a single Customer Dimension.
* **Business Rule Enforcement:** Automated sales calculations to ensure 100% accuracy in the Gold Layer.

---

## ğŸ› ï¸ How to Setup
Want to explore this warehouse locally?
1. **Clone the Repo:** `git clone https://github.com/JacobDaniel-82/sql-data-warehouse-project.git`
2. **Initialize DB:** Run `/scripts/init_database.sql` in SQL Server.
3. **Load Tables:** Run `/scripts/bronze/ddl_bronze.sql` and `/scripts/silver/ddl_silver.sql`.
4. **Execute ETL:** Run `EXEC bronze.load_bronze` then `EXEC Silver.load_silver`.

---

## ğŸ“… Roadmap & Project Evolution
This Data Warehouse serves as the foundation for a complete end-to-end data lifecycle. While this repository covers the **Data Engineering** infrastructure, the journey continues in the following phases:

* **âœ… Phase 2: Exploratory Data Analysis (EDA):** Completed. Investigated data distributions, identified key KPIs, and performed initial ranking analysis. 
* **âœ… Phase 3: Advanced Analytics:** Completed. Implemented YoY growth tracking, rolling averages, and complex customer segmentation (VIP/Regular/New).
* **ğŸ“Š Business Insights & Reporting:** Finalized. Curated high-level views designed for executive decision-making and BI tool consumption.

> [!IMPORTANT]
> **View the Results:** The full analytical breakdown, including SQL scripts for EDA and Advanced Analytics, can be found in the [Advanced Analytics & Insights Repository](https://github.com/JacobDaniel-82/sql-data-warehouse-analytics-insights).

---

## ğŸ¤ Let's Connect!

If you found this project interesting, Iâ€™d love to connect and chat about Data Engineering, Data Analytics, Business Intelligence. 

- **Explore More:** This is just one part of my journey. Check out my [ğŸ“‚ Full Portfolio](https://github.com/JacobDaniel-82) to see my projects.
- **Professional Network:** Let's stay in touch on [ğŸ’¼ LinkedIn](https://www.linkedin.com/in/jacobdanielr) (I'm active here!).
- **Get in Touch:** Have a question or a suggestion? Feel free to reach out via [ğŸ“§ Email](jacobdanielr82@gmail.com): jacobdanielr82@gmail.com

*Designed and Engineered by **Jacob Daniel R** | 2026*

---
